[project]
name = "datacontract-cli"
version = "0.10.20"
description = "The datacontract CLI is an open source command-line tool for working with Data Contracts. It uses data contract YAML files to lint the data contract, connect to data sources and execute schema and quality tests, detect breaking changes, and export to different formats. The tool is written in Python. It can be used as a standalone CLI tool, in a CI/CD pipeline, or directly as a Python library."
readme = "README.md"
authors = [
  { name = "Jochen Christ", email = "jochen.christ@innoq.com" },
  { name = "Stefan Negele", email = "stefan.negele@innoq.com" },
  { name = "Simon Harrer", email = "simon.harrer@innoq.com" },
]
classifiers = [
  "Programming Language :: Python :: 3",
  "License :: OSI Approved :: MIT License",
  "Operating System :: OS Independent",
]
requires-python = ">=3.10"
dependencies = [
  "typer>=0.15.1,<0.16",
  "pydantic>=2.8.2,<2.11.0",
  "pyyaml~=6.0.1",
  "requests>=2.31,<2.33",
  "fastjsonschema>=2.19.1,<2.22.0",
  "fastparquet==2024.11.0",
  "numpy>=1.26.4,<2.0.0", # transitive dependency, needs to be <2.0.0 https://github.com/datacontract/datacontract-cli/issues/575
  "python-multipart==0.0.20",
  "rich>=13.7,<13.10",
  "simple-ddl-parser==1.7.1",
  "duckdb==1.1.2",
  "soda-core-duckdb>=3.3.20,<3.4.0",
  # remove setuptools when https://github.com/sodadata/soda-core/issues/2091 is resolved
  "setuptools>=60",
  "python-dotenv~=1.0.0",
  "rdflib==7.0.0", # move to extra?
  "boto3>=1.34.41,<1.35.98",
  "jinja_partials >= 0.2.1",

]

[project.optional-dependencies]

avro = [
  "avro==1.12.0"
]

bigquery = [
  "soda-core-bigquery>=3.3.20,<3.4.0",
]

csv = [
  "clevercsv >= 0.8.2",
  "pandas >= 2.0.0",
]

databricks = [
  "soda-core-spark-df>=3.3.20,<3.4.0",
  "soda-core-spark[databricks]>=3.3.20,<3.4.0",
  "databricks-sql-connector>=3.7.0,<3.8.0",
  "databricks-sdk<0.41.0",
]

iceberg = [
  "pyiceberg==0.8.1"
]

kafka = [
  "datacontract-cli[avro]",
  "soda-core-spark-df>=3.3.20,<3.4.0"
]

postgres = [
  "soda-core-postgres>=3.3.20,<3.4.0"
]

s3 = [
  "s3fs==2024.12.0",
  "aiobotocore>=2.17.0,<2.18.0",
]

snowflake = [
  "snowflake-connector-python[pandas]>=3.6,<3.13",
  "soda-core-snowflake>=3.3.20,<3.4.0"
]

sqlserver = [
  "soda-core-sqlserver>=3.3.20,<3.4.0"
]

trino = [
  "soda-core-trino>=3.3.20,<3.4.0"
]

dbt = [
  "dbt-core>=1.8.0"
]

dbml = [
  "pydbml>=1.1.1"
]

parquet = [
  "pyarrow>=18.1.0"
]

web = [
  "fastapi==0.115.6",
  "uvicorn==0.34.0",
]

all = [
  "datacontract-cli[kafka,bigquery,csv,snowflake,postgres,databricks,sqlserver,s3,trino,dbt,dbml,iceberg,parquet,web]"
]

dev = [
  "datacontract-cli[all]",
  "httpx==0.28.1",
  "kafka-python",
  "moto==5.0.26",
  "pandas>=2.1.0",
  "pre-commit>=3.7.1,<4.1.0",
  "pytest",
  "pytest-xdist",
  "pymssql==2.3.2",
  "ruff",
  "testcontainers[minio,postgres,kafka,mssql]==4.9.0",
  "trino==0.332.0",
]

[project.urls]
Homepage = "https://cli.datacontract.com"
Issues = "https://github.com/datacontract/datacontract-cli/issues"

[project.scripts]
datacontract = "datacontract.cli:app"

[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[tool.pytest.ini_options]
#addopts = "-n 8" # run tests in parallel, you can disable parallel test execution with "pytest -n0" command
log_level = "INFO"
#log_cli = "true" #  activate live logging, do not use with -n 8 xdist option for parallel test execution: https://github.com/pytest-dev/pytest-xdist/issues/402
log_cli_level = "INFO"

[tool.ruff]
line-length = 120

[tool.ruff.lint]
extend-select = [
    "I",   # re-order imports in alphabetic order
]
